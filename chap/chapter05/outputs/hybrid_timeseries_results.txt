🚀 LSTM-Transformer 하이브리드 시계열 모델 결과
============================================================

📋 모델 설정:
   - 시퀀스 길이: 30
   - LSTM 유닛: 64
   - Attention 헤드: 4
   - Transformer 차원: 64

📊 성능 지표:
   - MSE: 65.8405
   - RMSE: 8.1142
   - MAE: 6.6712
   - R²: 0.6815

📈 데이터 정보:
   - 학습 샘플: 800
   - 테스트 샘플: 200
   - 예측 정확도: 68.2%
